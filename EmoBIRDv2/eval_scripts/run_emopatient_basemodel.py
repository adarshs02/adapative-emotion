#!/usr/bin/env python3
"""
Baseline runner: EmoPatient Ã— Base Model via OpenRouter (QA-only, no EmoBIRD pipeline)

- Reads scenarios from the EmoPatient dataset JSON (default: datasets/EmoPatient/scenarios.json)
- For each scenario's QA item, sends a single-turn prompt to a chosen OpenRouter model
- Writes a consolidated dataset-style JSON (like scenarios_30.json) with gt replaced by the model's response

Usage examples:
  export OPENROUTER_API_KEY=...  # required
  python EmoBIRDv2/eval_scripts/run_emopatient_basemodel.py --limit 1 --q-limit 2 --model openai/gpt-4o-mini --log-raw
  python EmoBIRDv2/eval_scripts/run_emopatient_basemodel.py --dataset-out /tmp/emopatient_basemodel.json --qa-retries 2

Notes:
- QA-only: each question is treated as a single-turn conversation: Context (narrative + optional metadata) + Question
- Change --model to switch base models easily (uses OpenRouter chat completions)
- If a QA's response is empty, the script will retry up to --qa-retries times
"""

from __future__ import annotations

import argparse
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import requests
from tqdm import tqdm

# Repo paths
SCRIPT_DIR = Path(__file__).resolve().parent
REPO_ROOT = SCRIPT_DIR.parent.parent
import sys
# Ensure package imports like 'from EmoBIRDv2.utils...' resolve when running directly
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

# EmoBIRDv2 constants (for defaults and timeouts)
from EmoBIRDv2.utils.constants import (
    OPENROUTER_API_KEY,
    MODEL_NAME as DEFAULT_MODEL,
    MODEL_TEMPERATURE as DEFAULT_TEMPERATURE,
    OPENROUTER_CONNECT_TIMEOUT,
    OPENROUTER_READ_TIMEOUT,
)

OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"


def ensure_api_key() -> None:
    if not OPENROUTER_API_KEY:
        raise RuntimeError("OPENROUTER_API_KEY environment variable is not set")


def load_emopatient(path: Path) -> List[Dict[str, Any]]:
    with path.open("r", encoding="utf-8") as f:
        data = json.load(f)
    scenarios = data.get("scenarios") if isinstance(data, dict) else None
    if not isinstance(scenarios, list):
        raise ValueError(f"Unexpected EmoPatient format in {path}")
    return scenarios


def format_user_prompt(scn: Dict[str, Any], question: str, *, include_meta: bool = True) -> str:
    title = str(scn.get("title", "")).strip()
    diagnosis = str(scn.get("diagnosis", "")).strip()
    treatment = str(scn.get("treatment_plan", "")).strip()
    narrative = str(scn.get("narrative", "")).strip()

    parts: List[str] = []
    if include_meta:
        if title:
            parts.append(f"Title: {title}")
        if diagnosis:
            parts.append(f"Diagnosis: {diagnosis}")
        if treatment:
            parts.append(f"Treatment plan: {treatment}")
    if narrative:
        parts.append(f"Narrative: {narrative}")

    parts.append("Question:")
    parts.append(question.strip())

    parts.append(
        "\nInstructions:\n"
        "You are an AI Chatbot."
        "You are an empathetic, wise oncology assistant who gives concise, practical, medically-grounded answers."
        "Given the context, Answer the question concisely (1-3 paragraphs).\n"
    )

    return "\n\n".join(parts).strip()


def call_openrouter_chat(*, api_key: str, model: str, temperature: float, max_tokens: int, system_prompt: Optional[str], user_prompt: str, connect_timeout: int, read_timeout: int) -> str:
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    messages: List[Dict[str, str]] = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": user_prompt})

    payload = {
        "model": model,
        "messages": messages,
        "temperature": float(temperature),
        "max_tokens": int(max_tokens),
    }
    resp = requests.post(
        OPENROUTER_URL,
        headers=headers,
        data=json.dumps(payload),
        timeout=(connect_timeout, read_timeout),
    )
    resp.raise_for_status()
    data = resp.json()
    try:
        return (data["choices"][0]["message"]["content"] or "").strip()
    except Exception:
        return ""


def run_for_question(
    *,
    scn: Dict[str, Any],
    question: str,
    model: str,
    temperature: float,
    max_tokens: int,
    system_prompt: Optional[str],
    attempts: int,
    log_raw: bool,
    connect_timeout: int,
    read_timeout: int,
) -> str:
    user_prompt = format_user_prompt(scn, question, include_meta=True)
    last: str = ""
    for i in range(1, attempts + 1):
        try:
            raw = call_openrouter_chat(
                api_key=OPENROUTER_API_KEY or "",
                model=model,
                temperature=temperature,
                max_tokens=max_tokens,
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                connect_timeout=connect_timeout,
                read_timeout=read_timeout,
            )
            if log_raw and raw:
                trunc = (raw[:2000] + "...[truncated]") if len(raw) > 2000 else raw
                print(f"[raw] {trunc}", file=sys.stderr)
        except Exception as e:
            print(f"[error] attempt {i}/{attempts} failed: {e}", file=sys.stderr)
            raw = ""
        if raw:
            last = raw
            break
    return last


def main() -> None:
    parser = argparse.ArgumentParser(description="Run base model over EmoPatient dataset (QA-only, OpenRouter)")
    parser.add_argument("--data", type=str, default=str(REPO_ROOT / "datasets" / "EmoPatient" / "scenarios_30.json"), help="Path to EmoPatient scenarios.json")
    parser.add_argument("--start", type=int, default=0, help="Start index (0-based) for scenarios")
    parser.add_argument("--limit", type=int, default=None, help="Process only N scenarios")
    parser.add_argument("--q-start", type=int, default=0, help="Start within QA list")
    parser.add_argument("--q-limit", type=int, default=None, help="Process only N questions per scenario")

    parser.add_argument("--model", type=str, default=DEFAULT_MODEL, help="OpenRouter model name (easily switch)")
    parser.add_argument("--temperature", type=float, default=DEFAULT_TEMPERATURE, help="Sampling temperature")
    parser.add_argument("--max-tokens", type=int, default=1536, help="Max new tokens for the answer")
    parser.add_argument("--system-prompt", type=str, default="You are an empathetic, wise oncology assistant who gives concise, practical, medically-grounded answers.", help="Optional system prompt")

    parser.add_argument("--attempts", type=int, default=5, help="Retries per QA call")
    parser.add_argument("--qa-retries", type=int, default=1, help="Additional re-runs if response is empty")
    parser.add_argument("--openrouter-connect-timeout", type=int, default=OPENROUTER_CONNECT_TIMEOUT, help="Connect timeout (s)")
    parser.add_argument("--openrouter-read-timeout", type=int, default=OPENROUTER_READ_TIMEOUT, help="Read timeout (s)")

    parser.add_argument("--dataset-out", type=str, default=None, help="Output consolidated dataset JSON path (gt replaced by base model response)")
    parser.add_argument("--log-raw", action="store_true", help="Print truncated raw model outputs to stderr")

    args = parser.parse_args()

    ensure_api_key()

    data_path = Path(args.data)
    scenarios = load_emopatient(data_path)

    start = max(0, int(args.start))
    end = len(scenarios) if args.limit is None else min(len(scenarios), start + int(args.limit))
    run_scenarios = list(enumerate(scenarios[start:end], start=start))

    run_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    print(f"Running EmoPatient x BaseModel: {len(run_scenarios)} scenarios | model={args.model} | run_id={run_id}", file=sys.stderr)

    consolidated: Dict[str, Any] = {"scenarios": []}

    for idx, scn in tqdm(run_scenarios, total=len(run_scenarios), desc="Scenarios", unit="scn"):
        sid = scn.get("id") or f"S{idx+1}"
        qa_list = scn.get("qa") if isinstance(scn.get("qa"), list) else []
        if not qa_list:
            print(f"[skip] {sid} has no QA entries; skipping.", file=sys.stderr)
            continue

        q_start = max(0, int(getattr(args, "q_start", 0)))
        q_end = len(qa_list) if args.q_limit is None else min(len(qa_list), q_start + int(args.q_limit))
        sub_qa = list(enumerate(qa_list[q_start:q_end], start=q_start))

        # Build output scenario (copy all fields except qa, then rebuild qa)
        scn_out: Dict[str, Any] = {}
        for k, v in scn.items():
            if k != "qa":
                scn_out[k] = v
        scn_out["qa"] = []

        for _pos, (j, qa) in enumerate(tqdm(sub_qa, total=len(sub_qa), desc=f"{sid} QA", unit="qa", leave=False), start=1):
            q_text = str(qa.get("q", "")).strip()
            if not q_text:
                scn_out["qa"].append(dict(qa))
                continue

            label = f"{sid} Q{j+1}/{q_end}"
            print(f"[{label}] running...", file=sys.stderr)

            answer = ""
            for rtry in range(max(0, int(args.qa_retries)) + 1):
                if rtry > 0:
                    print(f"[{label}] empty, retry {rtry}/{args.qa_retries}...", file=sys.stderr)
                answer = run_for_question(
                    scn=scn,
                    question=q_text,
                    model=args.model,
                    temperature=args.temperature,
                    max_tokens=args.max_tokens,
                    system_prompt=args.system_prompt,
                    attempts=args.attempts,
                    log_raw=args.log_raw,
                    connect_timeout=int(args.openrouter_connect_timeout),
                    read_timeout=int(args.openrouter_read_timeout),
                )
                if answer.strip():
                    break
                time.sleep(0.3)

            qa_out = dict(qa)
            qa_out["gt"] = answer.strip()
            scn_out["qa"].append(qa_out)

        consolidated["scenarios"].append(scn_out)

    # Pick default dataset path if not provided
    out_path = Path(args.dataset_out) if args.dataset_out else (REPO_ROOT / "EmoBIRDv2" / "eval_results" / "emopatient" / f"emopatient_basemodel_{run_id}.json")
    out_path.parent.mkdir(parents=True, exist_ok=True)
    with out_path.open("w", encoding="utf-8") as f:
        json.dump(consolidated, f, ensure_ascii=False, indent=2)
    print(f"[done] consolidated -> {out_path}", file=sys.stderr)


if __name__ == "__main__":
    main()