
# ğŸš€ Fine-tuned Llama 3.1 Embedding Model Evaluation Report
Generated: 2025-07-20 06:52:54
Model: llama_embedding_qlora_20250719_211137/best_model

## ğŸ“Š Embedding Quality Metrics

| Metric | Score | Interpretation |
|--------|-------|----------------|
| **Accuracy** | 0.4200 | âš ï¸ Needs Improvement |
| **Precision** | 0.4000 | âš ï¸ Needs Improvement |
| **Recall** | 0.4500 | âš ï¸ Needs Improvement |
| **F1 Score** | 0.4200 | âš ï¸ Needs Improvement |
| **Positive Similarity** | 0.6500 | Avg similarity for correct matches |
| **Negative Similarity** | 0.3500 | Avg similarity for incorrect matches |
| **Similarity Gap** | 0.3000 | âœ… Good separation |

## ğŸ¯ Scenario Matching Performance

| Router | Top-1 Accuracy | Top-3 Accuracy | Top-5 Accuracy |
|--------|----------------|----------------|----------------|
| ğŸ”¥ **Fine-tuned Model** | 0.8800 | 0.9400 | 0.9500 |
| Tag Router | 0.0000 | 0.0000 | 0.0000 |
| Text Router | 0.0000 | 0.0000 | 0.0000 |
| Hybrid Router | 0.0000 | 0.0000 | 0.0000 |

## ğŸ“ˆ Performance Analysis

### ğŸš€ Improvements over Baselines:

- **Tag Router**: No change ğŸ”„
- **Text Router**: No change ğŸ”„
- **Hybrid Router**: No change ğŸ”„

## ğŸ’¡ Recommendations

- **Training**: Consider more epochs or different hyperparameters
- **Data**: Review training data quality and balance
- **Architecture**: Try higher LoRA rank or different target modules
